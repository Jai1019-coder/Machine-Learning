{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import math\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', '#', 'I'),\n",
       " ('#', 'I', ' '),\n",
       " ('I', ' ', 'l'),\n",
       " (' ', 'l', 'o'),\n",
       " ('l', 'o', 'v'),\n",
       " ('o', 'v', 'e'),\n",
       " ('v', 'e', ' '),\n",
       " ('e', ' ', 'm'),\n",
       " (' ', 'm', 'a'),\n",
       " ('m', 'a', 'c'),\n",
       " ('a', 'c', 'h'),\n",
       " ('c', 'h', 'i'),\n",
       " ('h', 'i', 'n'),\n",
       " ('i', 'n', 'e')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams (character-level) from a given text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input text\n",
    "    n (int): Size of the n-grams\n",
    "\n",
    "    Returns:\n",
    "    list: A list of n-grams as tuples\n",
    "    \"\"\"\n",
    "    # Added padding with '#' characters to handle the start of sequences\n",
    "    padded_text = \"#\" * (n - 1) + text\n",
    "    ngrams = []\n",
    "    for i in range(len(padded_text) - n + 1):\n",
    "        ngram = tuple(padded_text[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams\n",
    "\n",
    "generate_ngrams(\"I love machine\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(corpus, n):\n",
    "    \"\"\"\n",
    "    Build an n-gram language model from the corpus.\n",
    "\n",
    "    Parameters:\n",
    "    corpus (str): Text corpus for building the model\n",
    "    n (int): Size of the n-grams\n",
    "\n",
    "    Returns:\n",
    "    dict: A probability distribution for each context\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = defaultdict(Counter)\n",
    "\n",
    "    # Generate n-grams\n",
    "    ngrams = generate_ngrams(corpus, n)\n",
    "\n",
    "    # Build the model\n",
    "    for ngram in ngrams:\n",
    "        context = ngram[:-1]  # all but the last character\n",
    "        char = ngram[-1]      # the last character\n",
    "        model[context][char] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    for context in model:\n",
    "        total_count = sum(model[context].values())\n",
    "        for char in model[context]:\n",
    "            model[context][char] = model[context][char] / total_count\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smoothing(model, vocabulary_size, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Apply smoothing to an n-gram model.\n",
    "\n",
    "    Parameters:\n",
    "    model (defaultdict): N-gram model.\n",
    "    vocabulary_size (int): Total number of unique characters in the vocabulary.\n",
    "    alpha (float): Smoothing parameter (default is 1.0).\n",
    "\n",
    "    Returns:\n",
    "    defaultdict: Smoothed n-gram model.\n",
    "    \"\"\"\n",
    "    smoothed_model = defaultdict(Counter)\n",
    "    for prefix, char_counts in model.items():\n",
    "        total_count = sum(char_counts.values()) + alpha * vocabulary_size\n",
    "        for char in char_counts:\n",
    "            smoothed_model[prefix][char] = (char_counts[char] + alpha) / total_count\n",
    "        for char in range(vocabulary_size):\n",
    "            if char not in char_counts:\n",
    "                smoothed_model[prefix][char] = alpha / total_count\n",
    "    return smoothed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating texts using N-Gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, n, start_text, length = 100):\n",
    "    \"\"\"\n",
    "    Generate text using N-Gram model.\n",
    "    Parameters : \n",
    "    model(dict) : trained n-gram model\n",
    "    n (int size) : size of n-gram model\n",
    "    start_text (str) : initial text to start generation\n",
    "    length(int) : number of characters to generate\n",
    "    Returns : Generated Text (str)\n",
    "    \"\"\"\n",
    "    #Initialise start_text\n",
    "    current_text = list(start_text)\n",
    "    \n",
    "    #Generate characters\n",
    "    for _ in range(length):\n",
    "        context = tuple(current_text[-n+1:]) if len(current_text) >= n-1 else tuple('#' * (n-1-len(current_text))+''.join(current_text))\n",
    "        if context not in model:\n",
    "            break\n",
    "        char_dist = model[context]\n",
    "        #Sample next character\n",
    "        chars,probs = zip(*char_dist.items())\n",
    "        next_char = random.choices(chars, weights=probs)[0]\n",
    "        #Append to current text\n",
    "        current_text.append(next_char)\n",
    "    return \"\".join(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text : he text amo \n"
     ]
    }
   ],
   "source": [
    "##Sample text\n",
    "text = \"hello world this is a sample text for testing the n-gram model.\"\n",
    "#Build the n-gram model\n",
    "bigram_model = build_ngram_model(text,2)\n",
    "##Generate text\n",
    "generated = generate_text(bigram_model,2,\"he\",10)\n",
    "print(f\"Generated Text : {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of model\n",
    "##### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, n , test_text):\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a given text using an n-gram model.\n",
    "\n",
    "    Parameters:\n",
    "    model (dict): N-gram model.\n",
    "    n (int): Size of the n-gram model.\n",
    "    test_text (str): Text to calculate perplexity for.\n",
    "\n",
    "    Returns:\n",
    "    float: Perplexity value.\n",
    "    \"\"\"\n",
    "    ngrams = generate_ngrams(test_text,n)\n",
    "    log_prob = 0\n",
    "    total_ngrams = len(ngrams)\n",
    "    for ngram in ngrams:\n",
    "        context = ngram[:-1]\n",
    "        char = ngram[-1]\n",
    "        if context in model and char in model[context]:\n",
    "            prob = model[context][char]\n",
    "            log_prob += -1 * math.log2(prob)\n",
    "        else:\n",
    "            return float('inf') #Return infinity for unseen n-grams\n",
    "        return 2**(log_prob/total_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training corpus\n",
    "training_corpus = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog.\n",
    "She sells seashells by the seashore.\n",
    "How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
    "To be or not to be, that is the question.\n",
    "All that glitters is not gold.\n",
    "A journey of a thousand miles begins with a single step.\n",
    "Actions speak louder than words.\n",
    "Beauty is in the eye of the beholder.\n",
    "Every cloud has a silver lining.\n",
    "Fortune favors the bold and brave.\n",
    "Life is like a box of chocolates.\n",
    "The early bird catches the worm.\n",
    "Where there's smoke, there's fire.\n",
    "Time heals all wounds and teaches all things.\n",
    "Knowledge is power, and power corrupts.\n",
    "Practice makes perfect, but nobody's perfect.\n",
    "The pen is mightier than the sword.\n",
    "When in Rome, do as the Romans do.\n",
    "A picture is worth a thousand words.\n",
    "Better late than never, but never late is better.\n",
    "Experience is the best teacher of all things.\n",
    "Laughter is the best medicine for the soul.\n",
    "Music soothes the savage beast within us.\n",
    "\"\"\"\n",
    "\n",
    "training_corpus = ''.join(c.lower() for c in training_corpus if c.isalnum() or c.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe quick brown fox jumps over the lazy dog\\nshe sells seashells by the seashore\\nhow much wood would a woodchuck chuck if a woodchuck could chuck wood\\nto be or not to be that is the question\\nall that glitters is not gold\\na journey of a thousand miles begins with a single step\\nactions speak louder than words\\nbeauty is in the eye of the beholder\\nevery cloud has a silver lining\\nfortune favors the bold and brave\\nlife is like a box of chocolates\\nthe early bird catches the worm\\nwhere theres smoke theres fire\\ntime heals all wounds and teaches all things\\nknowledge is power and power corrupts\\npractice makes perfect but nobodys perfect\\nthe pen is mightier than the sword\\nwhen in rome do as the romans do\\na picture is worth a thousand words\\nbetter late than never but never late is better\\nexperience is the best teacher of all things\\nlaughter is the best medicine for the soul\\nmusic soothes the savage beast within us\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build models of different orders \n",
    "def build_models(corpus):\n",
    "    models = {}\n",
    "    for n in [1,2,3]:\n",
    "        models[n] = build_ngram_model(corpus,n)\n",
    "        return models\n",
    "#Build the models\n",
    "models = build_models(training_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate samples and calculate perplexity\n",
    "def evaluate_samples(models, num_samples=10, sample_length = 40):\n",
    "    \"\"\"\n",
    "    Evaluate multiple n-gram models by generating text samples and calculating their perplexity scores.\n",
    "    \n",
    "    Parameters :\n",
    "    models : dict\n",
    "    Dictionay where keys are n-gram model size (eg. 2 for bigram model)\n",
    "    and values are trained n-gram models.\n",
    "\n",
    "    num_smaples : int, optional(default = 10)\n",
    "    Number of text samples to generate for each n-gram model.\n",
    "\n",
    "    sample_length : int, optional(default = 40)\n",
    "    length of each generated text sample in characters\n",
    "\n",
    "    \"\"\"\n",
    "    results = defaultdict(list)\n",
    "    for n, model in models.items():\n",
    "        print(f\"\\n=== {n}-gram Model Evaluation ===\")\n",
    "\n",
    "    # Generate multiple samples\n",
    "        start_text = training_corpus[:n-1]\n",
    "        for i in range(num_samples):\n",
    "        # Generate sample\n",
    "            generated = generate_text(model, n, start_text, sample_length)\n",
    "        \n",
    "        # Calculate perplexity\n",
    "            perplexity = calculate_perplexity(model, n, generated)\n",
    "        \n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            print(f\"Text: {generated}\")\n",
    "            print(f\"Perplexity: {perplexity:.2f}\")  \n",
    "            \n",
    "            results[n].append({\n",
    "                'text' : generated,\n",
    "                'perplexity' : perplexity\n",
    "            })\n",
    "\n",
    "        # Calculate average perplexity for this n-gram model\n",
    "\n",
    "        avg_perplexity = sum(sample['perplexity'] for sample in results[n]) / len(results[n])\n",
    "        \n",
    "        print(f\"\\nAverage Perplexity for {n}-gram Model: {avg_perplexity:.2f}\")\n",
    "    return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1-gram Model Evaluation ===\n",
      "\n",
      "Sample 1:\n",
      "Text: o\n",
      "Perplexity: 15.00\n",
      "\n",
      "Sample 2:\n",
      "Text: b\n",
      "Perplexity: 48.16\n",
      "\n",
      "Sample 3:\n",
      "Text: o\n",
      "Perplexity: 15.00\n",
      "\n",
      "Sample 4:\n",
      "Text: g\n",
      "Perplexity: 76.25\n",
      "\n",
      "Sample 5:\n",
      "Text: a\n",
      "Perplexity: 19.06\n",
      "\n",
      "Sample 6:\n",
      "Text:  \n",
      "Perplexity: 6.14\n",
      "\n",
      "Sample 7:\n",
      "Text: l\n",
      "Perplexity: 26.14\n",
      "\n",
      "Sample 8:\n",
      "Text: h\n",
      "Perplexity: 17.94\n",
      "\n",
      "Sample 9:\n",
      "Text: c\n",
      "Perplexity: 32.68\n",
      "\n",
      "Sample 10:\n",
      "Text: m\n",
      "Perplexity: 76.25\n",
      "\n",
      "Average Perplexity for 1-gram Model: 33.26\n",
      "\n",
      "== Overall Statistics ==\n",
      "\n",
      "1-gram Model Statistics:\n",
      "Minimum Perplexity: 6.14\n",
      "Maximum Perplexity: 76.25\n",
      "Average Perplexity: 33.26\n"
     ]
    }
   ],
   "source": [
    "# Evaluate samples\n",
    "results = evaluate_samples(models)\n",
    "\n",
    "# Calculate statistics for each model\n",
    "print(\"\\n== Overall Statistics ==\")\n",
    "for n in models.keys():\n",
    "    perplexities = [sample['perplexity'] for sample in results[n]]\n",
    "    min_perp = min(perplexities)\n",
    "    max_perp = max(perplexities)\n",
    "    avg_perp = sum(perplexities) / len(perplexities)\n",
    "    \n",
    "    print(f\"\\n{n}-gram Model Statistics:\")\n",
    "    print(f\"Minimum Perplexity: {min_perp:.2f}\")\n",
    "    print(f\"Maximum Perplexity: {max_perp:.2f}\")\n",
    "    print(f\"Average Perplexity: {avg_perp:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
